# HPC(high performance compute)
## 高性能计算的历史
    1.百万浮点运算（MFLOPs）

    2.每秒浮点运算（FLOPs）

    3.指令级并行性（ILP）

    4. GPU，最初主要用于图形处理。研究人员马克·哈里斯首次利用 GPU 进行了非图形任务，并创造了新术语使用 GPU 进行通用计算（GPGPU）。GPU 在某些数据并行类任务方面被证明是有效的。毫不奇怪，许多 HPC 应用程序中的大部分计算密集型任务在性质上都是数据并行的。它们主要是矩阵乘法，这在基本线性代数规范（BLAS）中是常规且广泛使用的。

## 异构计算，编程范式
    5.SIMD用于描述同一指令并行应用于多个数据点的体系结构。CPU指令集可以做到SIMD，个人观点：说明CPU有内有这样的结构；相比之下，在单指令多线程（SIMT）中，不是单个线程发出指令，而是多个线程向不同的数据发出相同的指令。与 SIMD 相比，GPU 体系结构更适合 SIMT 类别。

## 低延迟与高吞吐率

    6.GPU 架构被称为“减少延迟”或“高吞吐量架构”。GPU 架构通过来自其他线程的计算来隐藏延迟。当一个线程在等待数据可用进行计算时，其他线程可以开始执行，因此不会浪费任何时钟周期。如果您熟悉 CUDA，那么您可能已经了解到 warp 的概念。我们将在接下来的章节中介绍 warp 的概念。（在 CUDA 中，执行单元是 warp 而不是线程。因此，上下文切换发生在 warp 而不是线程之间）。

    7.CPU 架构是一种减少延迟的架构，寄存器->L1->L2->L3,由于 CPU 以非常高的时钟速度运行，因此有必要通过频繁地将使用的数据存储在缓存中并预测下一条要执行的指令来隐藏获取数据的延迟。可以最佳地利用 CPU 缓存的应用程序可以探索这种时间局部性。此外，可以利用填充指令管线的应用程序，例如代码中没有if和else语句的应用程序，通过隐藏获取指令的延迟来受益。因此，CPU 架构是一种减少延迟的架构。

    8.有些人可能已经在想为什么我们不能在 CPU 中创建这些线程并做同样的事情来隐藏延迟。原因是 GPU 有大量的寄存器，并且所有线程上下文切换信息已经存在于其中。这是最快的内存。然而，在 CPU 中，寄存器集是有限的，因此线程相关的信息通常存储在较低的内存层次结构中，比如缓存。例如，Volta 包含 20MB 的寄存器存储。因此，与 GPU 相比，CPU 中线程之间的上下文切换时间要长得多。

## GPU的编程方法

    9.现在，让我们回到我们最初的问题，即 CUDA 是什么？CUDA 是由 NVIDIA 开发的并行计算平台和编程模型架构，它将 GPU 上的通用计算作为一流能力进行暴露。与任何其他处理器一样，GPU 架构可以使用各种方法进行编码。提供快速加速的最简单方法是利用现有库。另外，开发人员可以选择使用 ***OpenACC 指令***以获得快速加速结果和可移植性。另一种选择是选择通过使用 C、C++、Fortran、Python 等语言构造来深入研究 CUDA，以获得最高的性能和灵活性。我们将在接下来的章节中详细介绍所有这些方法。


## 来自CUDA的hello world
    10.编译单个cu文件 nvcc -o hello_world hello_world.cu

    11.cudaDeviceSynchronize()，**CUDA中所有内核函数调用都是异步的**，在调用内核后，主机host变得空闲，并在之后开始执行下一条指令。这应该不足为奇，因为这是一个异构环境，因此主机和设备都可以运行，以利用可用的处理器类型。如果主机需要等待设备完成，CUDA编程提供API使主机代码设备函数完成，其中一个 API 是cudaDeviceSynchronize，它会等待所有先前对设备的调用完成。



## GPU架构

    13.CUDA 线程：CUDA 线程在 CUDA 核心上执行。CUDA 线程不同于 CPU 线程。CUDA 线程非常轻量级，并提供快速的上下文切换。快速上下文切换的原因是由于 GPU 中有大量的寄存器和硬件调度器。线程上下文存在于寄存器中，而不是像 CPU 中那样在较低的内存层次结构中，比如缓存中。因此，当一个线程处于空闲/等待状态时，另一个准备好的线程几乎可以立即开始执行。每个 CUDA 线程必须执行相同的内核，并且独立地处理不同的数据（SIMT）。

    14.CUDA 块：CUDA 线程被组合成一个称为 CUDA 块的逻辑实体。CUDA 块在单个流多处理器（SM）上执行。一个块在一个 SM 上运行，也就是说，一个块内的所有线程只能在一个 SM 的核心上执行，不会在其他 SM 的核心上执行。每个 GPU 可能有一个或多个 SM，因此为了有效地利用整个 GPU，用户需要将并行计算划分为块和线程。

    15.GRID/核心：CUDA 块被组合成一个称为 CUDA GRID 的逻辑实体。然后在设备上执行 CUDA GRID。

## 为啥要费心处理线程和块？

    16.线程和全局内存的合并，warp 内的线程如何从全局内存中访问数据非常重要，其中一种策略是改变数据布局以改善局部性。


学习链接：https://juejin.cn/post/7359525150549016612，实际上是对国外一本书的翻译