# 7.1概述
    编译器前端主要将用户代码进行解析翻译得到计算图IR，并对其进行设备信息无关的优化，此时的优化并不考虑程序执行的底层硬件信息。编译器后端的主要职责是对前端下发的IR做进一步的计算图优化，让其更加贴合硬件，并为IR中的计算节点选择在硬件上执行的算子，然后为每个算子的输入输出分配硬件内存，最终生成一个可以在硬件上执行的任务序列。


    前端IR是通过解析用户代码生成，属于高层次抽象，隐藏一些底层运行的细节信息

    后端优化基本流程 计算图优化(算子融合，复杂算子组合表达)----------->>算子选择（优化的IR图后选取最合适的目标设备算子的过程，IR往往可以映射成多种不同的硬件算子，如何组成高效算子，是算子选择核心问题）。算子选择本质上是一个模式匹配问题（编译器一般为一个IR节点有多个候选算子，高层次IR------》底层IR）------------------------》遍历算子序列，为每个算子分配相应的输入输出内存，算子加载到设备上执行计算。

## 7.1.1计算图优化
    1.优化内存IO为例：计算密集型，访存密集型算子，如Conv + Relu:二者融合来进行计算;
    2.算子拆解、算子聚合、算子重建减少内存访问.重建阶段，根据通用计算规则，生成高效的新算子在（硬件），以访存作为代价.
    3.计算图模式匹配来抵消比如NCHW->NC1HWC0->NCHW
### 7.1.1.1 特定硬件优化
    略
### 7.1.1.2 数据排布格式的限制
    内存中都是按行存储的数据格式
    RRRBBBGGG NCHW
## 7.1.2算子选择
    计算图优化后，需要对IR图上的每个节点进行算子选择，设备执行的算子序列。该阶段主要任务**根据IR图信息在众多算子中选择最合适的一个算子去目标设备上执行**。
    算子信息主要包括：1.数据排布格式、2.数据精度
    1.矩阵乘法的数据排布对于卷积优化也是一个关键要素(内存在按行是连续分布的)
    2.数据精度,常深度学习的系统，使用的是单精度(float32)表示。这种数据类型占用32位内存。还有一种精度较低的数据类型为半精度(float16)，其内部占用了16位的内存。由于很多硬件会对半精度数据类型进行优化，半精度的计算吞吐量可以是单精度的倍，且半精度占用的内存更小，这样可以输入更大的批大小(BatchSize)，进而减少总体训练时间。接下来详细看一下半精度浮点数与精度浮点数的区别。
### 7.1.2.1算子选择过程
    首先，选择算子执行的硬件设备。不同的硬件设备上，算子的实现、支持数据类型、执行效率通常会有所差别。这一步往往是用户自己指定的，若用户未指定，则编译器后端会为用户匹配一个默认的设备。 然后，后端会根据IR图中推导出的数据类型和内存排布格式选择对应的算子。
    理想情况下算子选择所选择出的算子类型，应该与用户预期的类型保持一致。软硬件限制，**存在一定的升精度和降精度**才能找到合适的匹配算子，算子之间的数据排布尽量要保持一致。
    总的来说，一个好的算子选择算法应该尽可能的保持数据类型与用户设置的数据类型一致，且尽可能少的出现数据格式转换
## 7.1.3内存分配
    内存在传统计算机存储器层次结构中有着重要的地位，它是连接高速缓存和磁盘之间的桥梁，有着比高速缓存更大的空间，比磁盘更快的访问速度。随着深度学习的发展，深度神经网络的模型越来越复杂，AI芯片上的内存很可能无法容纳一个大型网络模型。因此，对内存进行复用是一个重要的优化手段。此外，通过连续内存分配和 In-Place内存分配还可以提高某些算子的执行效率。
### 7.1.3.1内存分配
    内存分配模块主要负责给图中算子输入、输出分配device内存。编译器前端处理得到中间表达，后端根据中间表达进行算子选择和相关优化，可以得到算子最终的输入输出shape、datatype、format等信息，内存对齐优化访问速度。

    整个过程可以将待分配内存分成三种类型：一是整张图的输入张量，二是算子权重或属性，三是算子的输出张量，内存池管理内存。
    双游标法分配内存
### 内存复用
    贪心策略分配内存，
    
### In-Place算子
    在内存分配流程中，会为每个算子的输入和输出都分配不同的内存。然而对很多算子而言，为其分配不同的输入和输出地址，会浪费内存并且影响计算性能。例如优化器算子，其计算的目的就是更新神经网络的权重；例如Python语法中的 += 和 *= 操作符，将计算结果更新到符号左边的变量中；例如 a[0]=b 语法，将 a[0] 的值更新为 b。诸如此类计算有一个特点，都是为了更新输入的值。使用In-Palce

## 7.1.4计算调度执行
    经过算子选择与内存分配之后，计算任务可以通过运行时完成计算的调度与在硬件上的执行。根据是否将算子编译为计算图，计算的调度可以分为单算子调度与计算图调度两种方式。而根据硬件提供的能力差异，计算图的执行方式又可以分为逐算子下发执行的交互式执行以及将整个计算图或者部分子图一次性下发到硬件的下沉式执行两种模式。
### 7.1.4.1 单算子调度
    单算子调度是相对于计算图而言，算法或者模型中包含的算子通过Python语言的运行时被逐个调度执行。例如PyTorch的默认执行方式，TensorFlow的eager模式，以及MindSpore的PyNative模式。以MindSpore为例，如代码所示。
## 7.1.5. 算子编译器
    作为AI编译器中一个重要组成部分，算子编译器把单个简单或复杂的算子经过表达和优化后编译为一个单独的可执行文件。目前业界面对算子编译器仍有许多有趣的问题尚未得出明确结论，相关的处理逻辑与方法也尚未收敛,如何通过算子编译器进行性能优化？算子编译器如何兼容不同体系结构特点的芯片？面对输入Python代码的灵活性以及神经网络训练时动态性的情况，该如何充分将这些完美表达出来？